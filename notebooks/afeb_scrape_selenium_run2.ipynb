{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d98def7-c779-4f62-a733-62049f82bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fe393a-f451-49e4-94d4-ab579422e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=\"../logs/scrape.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048fc4cb-4536-4759-86c9-946dbac381ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = pd.read_csv(\n",
    "    \"../data/intermediate/companies_filling_minimal.csv\", index_col=0\n",
    ")\n",
    "companies[\"most_recent_filling\"] = pd.to_datetime(companies[\"most_recent_filling\"])\n",
    "companies_more_2006 = companies[companies[\"most_recent_filling\"].dt.year > 2006]\n",
    "companies_more_2008 = companies[companies[\"most_recent_filling\"].dt.year > 2008]\n",
    "\n",
    "ciks = list(companies_more_2008[\"CIK\"])\n",
    "len(ciks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2c3664-d616-484d-a6b5-5b6c71aef36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Anselme F.E. Borgeaud (aborgeaud@gmail.com)\"}\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3f2cfc-4bb4-41da-86b8-10553840d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_balance_sheet(df):\n",
    "    ncol = len(df.columns)\n",
    "    has_assets = df.iloc[:, 0].astype(\"string\").str.contains(r\"Assets\").sum() > 0\n",
    "    has_cash_equivs = []\n",
    "    has_cashs = []\n",
    "    has_total_liabs = []\n",
    "    has_equities = []\n",
    "    has_debts = []\n",
    "    for icol in range(min(ncol, 3)):\n",
    "        has_cash_equivs.append(\n",
    "            df.iloc[:, icol]\n",
    "            .astype(\"string\")\n",
    "            .str.contains(r\"[cC]ash.*[eE]quivalent.*\")\n",
    "            .sum()\n",
    "            > 0\n",
    "        )\n",
    "        has_cashs.append(\n",
    "            df.iloc[:, icol].astype(\"string\").str.contains(r\"[cC]ash\").sum() > 0\n",
    "        )\n",
    "        has_total_liabs.append(\n",
    "            df.iloc[:, icol].astype(\"string\").str.contains(r\"Total.*liabilities\").sum()\n",
    "            > 0\n",
    "        )\n",
    "        has_debts.append(\n",
    "            df.iloc[:, icol].astype(\"string\").str.contains(r\"Long-term debt\").sum() > 0\n",
    "        )\n",
    "        has_equities.append(\n",
    "            df.iloc[:, icol]\n",
    "            .astype(\"string\")\n",
    "            .str.contains(r\"Total stockholder.*equity\")\n",
    "            .sum()\n",
    "            > 0\n",
    "        )\n",
    "\n",
    "    has_cash = any(has_cash_equivs) or any(has_cashs)\n",
    "    has_liab = any(has_total_liabs)\n",
    "    has_debt = any(has_debts)\n",
    "    has_equity = any(has_equities)\n",
    "\n",
    "    return has_cash and has_equity and has_assets and (has_debt or has_liab)\n",
    "\n",
    "\n",
    "def find_index_col(df):\n",
    "    index_col = \"\"\n",
    "    i_index_col = 0\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if df.loc[:, col].astype(\"str\").str.contains(\"Assets\").any():\n",
    "            index_col = col\n",
    "            i_index_col = i\n",
    "    return i_index_col, index_col\n",
    "\n",
    "\n",
    "def is_finite(x):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        return np.isfinite(f)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_balance(df):\n",
    "    i, index_col = find_index_col(df)\n",
    "    arr = df.to_numpy()[:, i:]\n",
    "    mask = [type(x) == str for x in arr[:, 0]]\n",
    "    arr = arr[mask, :]\n",
    "    data = np.apply_along_axis(lambda x: get_value(x), 1, arr)\n",
    "    index = arr[:, 0]\n",
    "    df = pd.DataFrame({\"value\": data}, index=index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_balance_sheet_2(table):\n",
    "    content = table.text.lower()\n",
    "    has_assets = (len(re.findall(r\"current.*assets\", content, re.DOTALL)) > 0) or (\n",
    "        len(re.findall(r\"total.*assets\", content, re.DOTALL)) > 0\n",
    "    )\n",
    "    has_liab = (len(re.findall(r\"total.*liabilities\", content, re.DOTALL)) > 0) or (\n",
    "        len(re.findall(r\"current.*liabilities\", content, re.DOTALL)) > 0\n",
    "    )\n",
    "    has_cash = \"cash\" in table.text.lower()\n",
    "    has_equity = \"equity\" in table.text.lower()\n",
    "    has_asset = \"assets\" in table.text.lower()\n",
    "    return has_asset and has_assets and has_liab and has_cash and has_equity\n",
    "\n",
    "\n",
    "def get_balance_table_2(soup):\n",
    "    tables = soup.findAll(\"table\")\n",
    "    balance_tables = [t for t in tables if is_balance_sheet_2(t)]\n",
    "    if len(balance_tables) == 0:\n",
    "        return None\n",
    "    i_longest = 0\n",
    "    longest = 0\n",
    "    for i, table in enumerate(balance_tables):\n",
    "        if len(table) > longest:\n",
    "            i_longest = i\n",
    "            longest = len(table)\n",
    "    balance_table = balance_tables[i_longest]\n",
    "    dfs = pd.read_html(balance_table.prettify(), flavor=\"bs4\")\n",
    "    if len(dfs) == 1:\n",
    "        return dfs[0]\n",
    "\n",
    "\n",
    "def get_value(x):\n",
    "    vals = [v for v in x if is_finite(v)]\n",
    "    try:\n",
    "        val = float(vals[0]) * 1000\n",
    "    except:\n",
    "        return None\n",
    "    return val\n",
    "\n",
    "\n",
    "def get_date(soup):\n",
    "    ps = soup.findAll(\"p\")\n",
    "    bs = soup.findAll(\"b\")\n",
    "    texts = [\n",
    "        p.get_text(strip=True).replace(u\"\\xa0\", u\" \")\n",
    "        for p in ps + bs\n",
    "        if \"fiscal year ended\" in p.text\n",
    "    ]\n",
    "    if len(texts) > 0:\n",
    "        match = re.findall(r\"ended .*[0-9]{4}\", texts[0])\n",
    "        if len(match) == 1:\n",
    "            date_str = match[0].replace(\"ended \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date_str, \"%B %d, %Y\")\n",
    "                return date\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "def get_balance_table(soup):\n",
    "    bs = soup.findAll(\"b\")\n",
    "    b_balance = [b for b in bs if \"consolidated balance sheet\" in b.text.lower()][0]\n",
    "    parent = b_balance.find_parent(\"div\")\n",
    "    i = 0\n",
    "    table = None\n",
    "    while (table is None) and (i < 4):\n",
    "        parent = parent.find_next_sibling(\"div\")\n",
    "        table = parent.find(\"table\")\n",
    "        i += 1\n",
    "\n",
    "    try:\n",
    "        return pd.read_html(table.prettify(), flavor=\"bs4\")[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934dea4d-2423-47f5-bcd9-afa10d9b8a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████▍                                                        | 2310/4625 [3:18:46<2:46:41,  4.32s/it]"
     ]
    }
   ],
   "source": [
    "dfs_parsed = []\n",
    "financial_report_urls = []\n",
    "\n",
    "for i, cik in enumerate(tqdm(ciks)):\n",
    "    if i % 30 == 0:\n",
    "        file = f\"../data/intermediate/df_parsed{time.time_ns()}.pickle\"\n",
    "        file_report = f\"../data/intermediate/report_urls{time.time_ns()}.pickle\"\n",
    "        with open(file, \"wb\") as f:\n",
    "            pickle.dump(dfs_parsed, f)\n",
    "        with open(file_report, \"wb\") as f:\n",
    "            pickle.dump(financial_report_urls, f)\n",
    "\n",
    "    url = f\"https://www.sec.gov/edgar/browse/?CIK={cik}\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    time.sleep(4)\n",
    "\n",
    "    try:\n",
    "        search_elem = driver.find_element_by_xpath(\n",
    "            '//input[@placeholder=\"Search table\"]'\n",
    "        )\n",
    "        search_elem.send_keys(\"10-K \")  # blank space to avoid 10-K/A (amendments)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    link_elems = driver.find_elements_by_class_name(\"document-link\")\n",
    "    annual_report_elems = [e for e in link_elems if \"Annual report\" in e.text]\n",
    "    annual_report_pages = []\n",
    "\n",
    "    for annual_report_elem in annual_report_elems:\n",
    "        try:\n",
    "            resp = requests.get(\n",
    "                annual_report_elem.get_property(\"href\"), headers=headers, timeout=4\n",
    "            )\n",
    "            annual_report_pages.append(resp)\n",
    "        except:\n",
    "            href_elem = a.get_property(\"href\")\n",
    "            logging.info(f\"{href_elem} Did not fetch report page\")\n",
    "            pass\n",
    "\n",
    "    financial_report_urls.extend([a.get_property(\"href\") for a in annual_report_elems])\n",
    "\n",
    "    for i, page in enumerate(annual_report_pages):\n",
    "        soup = BeautifulSoup(page.content)\n",
    "\n",
    "        try:\n",
    "            date_str = driver.find_elements_by_xpath(\n",
    "                '//a[@data-index=\"reportDate\"]'\n",
    "            )[i].text\n",
    "            date = datetime.fromisoformat(date_str)\n",
    "        except:\n",
    "            logging.info(f\"{page.url} Did not read date\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            balance_sheet = get_balance_table_2(soup)\n",
    "            if balance_sheet is None:\n",
    "                logging.info(f\"{page.url} Did not read html\")\n",
    "                continue\n",
    "            balance_sheet = process_balance(balance_sheet)\n",
    "        except:\n",
    "            logging.info(f\"{page.url} Did not read html\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            add_info = pd.DataFrame(\n",
    "                data={'value': [date, cik, page.url]}, index=[\"date_filled\", \"CIK\", \"url\"]\n",
    "            )\n",
    "            balance_sheet = balance_sheet.append(add_info)\n",
    "            balance_sheet = balance_sheet.transpose().reset_index(drop=True)\n",
    "        except:\n",
    "            logging.info(f\"{page.url} Did not make final dataframe\")\n",
    "            pass\n",
    "\n",
    "        if balance_sheet is not None:\n",
    "            logging.info(f\"{page.url} added\")\n",
    "            dfs_parsed.append(balance_sheet)\n",
    "\n",
    "\n",
    "with open(\"../data/intermediate/df_parsed_2.pickle\", \"wb\") as f:\n",
    "    pickle.dump(dfs_parsed, f)\n",
    "\n",
    "with open(\"../data/intermediate/report_urls.pickle\", \"wb\") as f:\n",
    "    pickle.dump(financial_report_urls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debe6de-bf44-4358-a028-213e0047a672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propulsion",
   "language": "python",
   "name": "propulsion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
