{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d98def7-c779-4f62-a733-62049f82bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8fe393a-f451-49e4-94d4-ab579422e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import tempfile\n",
    "from collections import defaultdict\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=\"../logs/scrape.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048fc4cb-4536-4759-86c9-946dbac381ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = pd.read_csv(\n",
    "    \"../data/intermediate/companies_filling_minimal.csv\", index_col=0\n",
    ")\n",
    "companies[\"most_recent_filling\"] = pd.to_datetime(companies[\"most_recent_filling\"])\n",
    "companies_more_2006 = companies[companies[\"most_recent_filling\"].dt.year > 2006]\n",
    "companies_more_2008 = companies[companies[\"most_recent_filling\"].dt.year > 2008]\n",
    "\n",
    "ciks = list(companies_more_2008[\"CIK\"])\n",
    "len(ciks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2c3664-d616-484d-a6b5-5b6c71aef36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Anselme F.E. Borgeaud (aborgeaud@gmail.com)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d70913-4f2e-4425-8328-6abbc9e281e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_balance_sheet(df):\n",
    "    ncol = len(df.columns)\n",
    "    has_assets = df.iloc[:, 0].astype(\"string\").str.contains(r\"Assets\").sum() > 0\n",
    "    has_cash_equivs = []\n",
    "    has_cashs = []\n",
    "    has_total_liabs = []\n",
    "    has_equities = []\n",
    "    has_debts = []\n",
    "    for icol in range(min(ncol, 3)):\n",
    "        has_cash_equivs.append(\n",
    "            df.iloc[:, icol]\n",
    "            .astype(\"string\")\n",
    "            .str.contains(r\"[cC]ash.*[eE]quivalent.*\")\n",
    "            .sum()\n",
    "            > 0\n",
    "        )\n",
    "        has_cashs.append(\n",
    "            df.iloc[:, icol].astype(\"string\").str.contains(r\"[cC]ash\").sum() > 0\n",
    "        )\n",
    "        has_total_liabs.append(\n",
    "            df.iloc[:, icol].astype(\"string\").str.contains(r\"Total.*liabilities\").sum()\n",
    "            > 0\n",
    "        )\n",
    "        has_debts.append(\n",
    "            df.iloc[:, icol].astype(\"string\").str.contains(r\"Long-term debt\").sum() > 0\n",
    "        )\n",
    "        has_equities.append(\n",
    "            df.iloc[:, icol]\n",
    "            .astype(\"string\")\n",
    "            .str.contains(r\"Total stockholder.*equity\")\n",
    "            .sum()\n",
    "            > 0\n",
    "        )\n",
    "\n",
    "    has_cash = any(has_cash_equivs) or any(has_cashs)\n",
    "    has_liab = any(has_total_liabs)\n",
    "    has_debt = any(has_debts)\n",
    "    has_equity = any(has_equities)\n",
    "\n",
    "    return has_cash and has_equity and has_assets and (has_debt or has_liab)\n",
    "\n",
    "\n",
    "def find_index_col(df):\n",
    "    index_col = \"\"\n",
    "    i_index_col = 0\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if df.loc[:, col].astype(\"str\").str.contains(\"Assets\").any():\n",
    "            index_col = col\n",
    "            i_index_col = i\n",
    "    return i_index_col, index_col\n",
    "\n",
    "\n",
    "def is_finite(x):\n",
    "    try:\n",
    "        f = float(x)\n",
    "        return np.isfinite(f)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_balance(df):\n",
    "    i, index_col = find_index_col(df)\n",
    "    arr = df.to_numpy()[:, i:]\n",
    "    mask = [type(x) == str for x in arr[:, 0]]\n",
    "    arr = arr[mask, :]\n",
    "    data = np.apply_along_axis(lambda x: get_value(x), 1, arr)\n",
    "    index = arr[:, 0]\n",
    "    df = pd.DataFrame({\"value\": data}, index=index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_balance_sheet_2(table):\n",
    "    content = table.text.lower()\n",
    "    has_assets = (len(re.findall(r\"current.*assets\", content, re.DOTALL)) > 0) or (\n",
    "        len(re.findall(r\"total.*assets\", content, re.DOTALL)) > 0\n",
    "    )\n",
    "    has_liab = (len(re.findall(r\"total.*liabilities\", content, re.DOTALL)) > 0) or (\n",
    "        len(re.findall(r\"current.*liabilities\", content, re.DOTALL)) > 0\n",
    "    )\n",
    "    has_cash = \"cash\" in table.text.lower()\n",
    "    has_equity = \"equity\" in table.text.lower()\n",
    "    has_asset = \"assets\" in table.text.lower()\n",
    "    return has_asset and has_assets and has_liab and has_cash and has_equity\n",
    "\n",
    "\n",
    "def get_balance_table_2(soup):\n",
    "    tables = soup.findAll(\"table\")\n",
    "    balance_tables = [t for t in tables if is_balance_sheet_2(t)]\n",
    "    if len(balance_tables) == 0:\n",
    "        return None\n",
    "    i_longest = 0\n",
    "    longest = 0\n",
    "    for i, table in enumerate(balance_tables):\n",
    "        if len(table) > longest:\n",
    "            i_longest = i\n",
    "            longest = len(table)\n",
    "    balance_table = balance_tables[i_longest]\n",
    "    dfs = pd.read_html(balance_table.prettify(), flavor=\"bs4\")\n",
    "    if len(dfs) == 1:\n",
    "        return dfs[0]\n",
    "\n",
    "\n",
    "def get_value(x):\n",
    "    vals = [v for v in x if is_finite(v)]\n",
    "    try:\n",
    "        val = float(vals[0]) * 1000\n",
    "    except:\n",
    "        return None\n",
    "    return val\n",
    "\n",
    "\n",
    "def get_date(soup):\n",
    "    ps = soup.findAll(\"p\")\n",
    "    bs = soup.findAll(\"b\")\n",
    "    texts = [\n",
    "        p.get_text(strip=True).replace(u\"\\xa0\", u\" \")\n",
    "        for p in ps + bs\n",
    "        if \"fiscal year ended\" in p.text\n",
    "    ]\n",
    "    if len(texts) > 0:\n",
    "        match = re.findall(r\"ended .*[0-9]{4}\", texts[0])\n",
    "        if len(match) == 1:\n",
    "            date_str = match[0].replace(\"ended \", \"\")\n",
    "            try:\n",
    "                date = datetime.strptime(date_str, \"%B %d, %Y\")\n",
    "                return date\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "\n",
    "def get_balance_table(soup):\n",
    "    bs = soup.findAll(\"b\")\n",
    "    b_balance = [b for b in bs if \"consolidated balance sheet\" in b.text.lower()][0]\n",
    "    parent = b_balance.find_parent(\"div\")\n",
    "    i = 0\n",
    "    table = None\n",
    "    while (table is None) and (i < 4):\n",
    "        parent = parent.find_next_sibling(\"div\")\n",
    "        table = parent.find(\"table\")\n",
    "        i += 1\n",
    "\n",
    "    try:\n",
    "        return pd.read_html(table.prettify(), flavor=\"bs4\")[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_value(row_elem):\n",
    "    def is_number(s):\n",
    "        return len(re.findall(r\"[0-9]+\", s)) > 0\n",
    "\n",
    "    elem = row_elem.find_next_sibling(\"td\")\n",
    "    if elem is None:\n",
    "        return None\n",
    "    i = 0\n",
    "    while not is_number(elem.text) and i < 4:\n",
    "        elem = elem.find_next_sibling(\"td\")\n",
    "    if is_number(elem.text):\n",
    "        try:\n",
    "            return float(elem.text.replace(\",\", \"\"))\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "\n",
    "def find_value_in_table(soup, key: str) -> float:\n",
    "    key_elem = None\n",
    "    key_text = key.strip().replace(\"\\n\", \"_\").replace(\" \", \"_\").lower()\n",
    "    for e in soup.findAll(\"td\"):\n",
    "        text = e.text.strip().replace(\"\\n\", \"_\").replace(\" \", \"_\").lower()\n",
    "        if key_text == text:\n",
    "            key_elem = e\n",
    "    if key_elem:\n",
    "        return find_value(key_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0436d31a-add4-404a-b312-33c113483b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [\"total_current_assets\", \"total_current_liabilities\"]\n",
    "\n",
    "\n",
    "def run(ciks: list):\n",
    "    driver = webdriver.Chrome()\n",
    "    time.sleep(8)\n",
    "\n",
    "    report_urls = []\n",
    "    data_dict = defaultdict(list)\n",
    "    data_df = None\n",
    "\n",
    "    for i, cik in enumerate(tqdm(ciks)):\n",
    "        if (i > 0) and (i % 30 == 0):\n",
    "            timestamp = time.time_ns()\n",
    "            file_report = f\"../data/intermediate/report_urls{timestamp}.pickle\"\n",
    "            with open(file_report, \"wb\") as f:\n",
    "                pickle.dump(report_urls, f)\n",
    "            data_df = pd.DataFrame(data_dict)\n",
    "            data_df.to_csv(f\"../data/intermediate/scraped_financials{timestamp}.csv\")\n",
    "\n",
    "        url = f\"https://www.sec.gov/edgar/browse/?CIK={cik}\"\n",
    "        try:\n",
    "            driver.get(url)\n",
    "        except:\n",
    "            logging.info(f\"{url} Did not get page\")\n",
    "            continue\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "        try:\n",
    "            search_elem = driver.find_element_by_xpath(\n",
    "                '//input[@placeholder=\"Search table\"]'\n",
    "            )\n",
    "            search_elem.send_keys(\"10-K \")  # blank space to avoid 10-K/A (amendments)\n",
    "        except:\n",
    "            logging.info(f\"{url} Did not input 10-K\")\n",
    "            continue\n",
    "\n",
    "        link_elems = driver.find_elements_by_class_name(\"document-link\")\n",
    "        annual_report_elems = [e for e in link_elems if \"Annual report\" in e.text]\n",
    "        annual_report_pages = []\n",
    "\n",
    "        for annual_report_elem in annual_report_elems:\n",
    "            try:\n",
    "                resp = requests.get(\n",
    "                    annual_report_elem.get_property(\"href\"), headers=headers, timeout=5\n",
    "                )\n",
    "                annual_report_pages.append(resp)\n",
    "            except:\n",
    "                href_elem = a.get_property(\"href\")\n",
    "                logging.info(f\"{href_elem} Did not fetch report page\")\n",
    "                pass\n",
    "\n",
    "        report_urls.extend([a.get_property(\"href\") for a in annual_report_elems])\n",
    "\n",
    "        for i, page in enumerate(annual_report_pages):\n",
    "            soup = BeautifulSoup(page.content)\n",
    "\n",
    "            try:\n",
    "                date_str = driver.find_elements_by_xpath(\n",
    "                    '//a[@data-index=\"reportDate\"]'\n",
    "                )[i].text\n",
    "                date = datetime.fromisoformat(date_str)\n",
    "            except:\n",
    "                logging.info(f\"{page.url} Did not read date\")\n",
    "                continue\n",
    "\n",
    "            tmp_dict = None\n",
    "            try:\n",
    "                tmp_dict = dict()\n",
    "                for entry in entries:\n",
    "                    tmp_dict[entry] = find_value_in_table(soup, entry)\n",
    "            except:\n",
    "                logging.info(f\"{page.url} Did not read html\")\n",
    "                continue\n",
    "            if (tmp_dict.keys() - set(entries)) == set():\n",
    "                for entry, value in tmp_dict.items():\n",
    "                    data_dict[entry].append(value)\n",
    "                data_dict[\"CIK\"].append(cik)\n",
    "                data_dict[\"date_filled\"].append(date)\n",
    "                data_dict[\"url\"].append(page.url)\n",
    "\n",
    "    data_df = pd.DataFrame(data_dict)\n",
    "    data_df.to_csv(\"../data/intermediate/scraped_financials.csv\")\n",
    "\n",
    "    with open(\"../data/intermediate/report_urls.pickle\", \"wb\") as f:\n",
    "        pickle.dump(report_urls, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ea7599-0b67-4b82-a760-cf3a6d5f87ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1541, 3082, 4625]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(ciks)\n",
    "print(n)\n",
    "splits = [n // 3 * i for i in range(4)]\n",
    "splits[-1] = n\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7d696b-97d7-405c-819d-01afa9c5a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1541/1541 [2:24:41<00:00,  5.63s/it]\n"
     ]
    }
   ],
   "source": [
    "run(ciks[splits[0] : splits[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ccbe7-a099-40c5-ac48-989457321b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propulsion",
   "language": "python",
   "name": "propulsion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
